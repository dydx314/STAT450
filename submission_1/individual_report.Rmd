---
title: 'STAT 450 Project: Predicting Condo Prices'
author: "David Yin, 13922159"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Summary

The client is a real estate agent in Metro Vancouver who actively buys and sells mainly condo homes for her clients. She is interested in knowing the potential values of condo homes in three neighborhoods: Collingwood, Metrotown, and Whalley. Statistical methods were performed on the data provided to determine trends in condo price and estimate future condo price per square foot. Exploratory analysis has shown that the BC Investment Immigration Program preceeded a large boost in condo price. A forecast using Seasonal ARIMA has been fairly accurate for Collingwood and Whalley but not so much for Metrotown. Random forest, which predicts price based on multiple characteristics associated with a condo, has given us a prediction error of 6.7% for Collingwood, 7.8% for Metrotown, and 7.7% for Whalley. 

## Introduction

Our aim is to predict the monthly resale condo price per square foot in 2018, for each of the three sub-regions in the Greater Vancouver area. They are Collingwood, Metrotown and Whalley. We also seek to identify which region have a high growth potential. Additionally, we hope to analyze the potential sales growth of condos of different sizes in 2018.

Once we have accomplished these goals, we plan on comparing our predictions for December 2017 and January 2018 with market data to see how well our models work. Moreover, we would like to see if our predictions are consistent with those done by Statistics Canada or other institutes.


## Data Description

To address these problems, we will use sales records on MLSLink (https://idp.gvfv.clareitysecurity.net). We intend on obtaining information on condos in the three aforementioned regions from 01/01/2006 to 12/31/2017. The variables we intend on using, from this dataset, are:  
  
- Price  
- Days on Market  
- Total Bedroom  
- Total Floor Area  
- Age  
- Year Built  
- Address  
- Bylaw Restrictions (such as pet allowance).  
  
We hope to also collect external data on variables whose characteristics we believe have an association with condo prices. They include but are not limited to:  
  
- Population (census data) - available for years 2006, 2011 and 2016  
- Foreign exchange rate (forex.com)  
- Government policies, such as the 15% foreign buyer tax implemented in 2016  
- Interest rate (bank of canada)  
- School ranking in the regions (various sites)  

We did some data cleaning to make sure that outliers were excluded from our model. For example, abnormally old condos were excluded, as well as those without a price shown.




## Methods

### Exploratory Analysis

Before predicting the future of Greater Vancouver's real estate market, it is better for us to understand what has happened in the past. Hence, we used exploratory data analysis (EDA) to visualize the main characteristics of our data. EDA mainly focuses on checking assumptions, handling missing values and making necessary transformations of variables, which make it a good approach to explore the data and see what it suggests before model fitting or hypothesis testing.  For example, by plotting the price of condos with respect to their age, we found that the condos with age of 999 were extremely old and would affect the accuracy of our model fitting, so we removed the data of such condos as outliers.  
  
The visualization package we used in R is called "ggplot", which allows us to construct the initial plot object and add other components to the plot. We included external factors such as foreign currency exchange rates and government policies in the plots. Again, it helped us visualize their influences on the condo market. 

### ARIMA

To analyze the time series data, we decided to use AutoRegressive Integrated MovingAverage (ARIMA) model with an assumption that the price per square foot depends on both previous prices and white noise. We mainly used auto.arima function, which is part of R's forecast package, to make predictions. 

auto.arima searches through multiple combinations of ARIMA parameters and selects the set that optimizes the model fit criteria. In addition, auto.arima is flexible enough to handle seasonal effect and trend in the time series data.

For each district, the time series data from January 2006 to September 2017 was used to fit the ARIMA model. Then, we used the fitted model to predict the price per square foot from October to December in 2017. 

The blue line in the following three plots represents the prediction generated by the fitted ARIMA models. The black line represents the actual observed values. The dark grey and light grey shaded regions represent 95% and 80% confidence interval, respectively.


### Random Forest

We would also like to look at how different variables can help us predict condo prices. Unlike ARIMA which is fitted to time series data, a random forest allows us to analyze our data from a different perspective. Random forest is a statistics method used to build predictive models for classification or regression models. It involves the use of ensembling the predictions of multiple decision trees. We will use it to predict monthly average price per square foot based on the relevant characteristics identified previously in our *Data Description* section.

To assess the performance of our model, we will use a technique called cross-validation. Cross-validation allows us to break our data into random training and testing sets, using the training set to predict on the testing set. This will be done several times, with random training and testing sets each time, so we can get a measure of the prediction error for our random forest model. 

Again unlike our ARIMA prediction, instead of predicting an average market price for condos, our random forest model requires a specific condo with all of the relevant charateristics listed in our variable list (see results section below) in order to predict the price of that specific condo.



## Results: Exploratory Analysis

```{r data, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(rstudioapi)
load("clean_data.RData")
```

```{r price, echo=FALSE, warning=FALSE, message=FALSE}
collingwood <- subset(full_data, Neighborhood == "Collingwood" & !is.na(Sold.Price.per.SqFt))
metrotown <- subset(full_data, Neighborhood == "Metrotown" & !is.na(Sold.Price.per.SqFt))
whalley <- subset(full_data, Neighborhood == "Whalley" & !is.na(Sold.Price.per.SqFt))


ggplot(collingwood[collingwood$Age < 60, ], aes(x = Age, y = Sold.Price.per.SqFt)) + geom_point() + geom_smooth(method = "lm") + ylab("Sold Price per Sqft")
ggplot(collingwood, aes(y = Sold.Price.per.SqFt, x = StratMtFee)) + geom_point() + geom_smooth(method = "lm")
ggplot(collingwood, aes(x = List.Date, y = Sold.Price.per.SqFt)) + geom_point() + geom_smooth()
```

We loaded two history records of currency exchange rate, Canadian Dollar (CAD)  versus US Dollar (USD), and CAD versus Chinese Yuan (CNY). We chose Chinese Yuan because Chinese citizens made up the largest buyer group in Vancouver's property market. Both of USD and CNY became stronger against CAD after 2014, due to Canadian economic recession. Meanwhile, we noticed an opposite trend in Vancouver's housing market. The housing price was stable before 2014, since then, it went up rapidly.  

Due to the poor housing affordability, the City of Vancouver have come up with some policies trying to address this issue. During the past two years, they have implemented "First Time Home Buyers' Program", "Empty Homes Tax", "15% Foreign Buyer Tax". The client was interested to see how these policies affected the condo market and if the foreign buyer tax would continue affecting the market as the tax rate would increase five more percent this year (note: to-do prediction). We also included "BC Investment Immigration Program" and the 2008 Financing Crisis since it was believed that they had influences on Vancouver's real estate market.  
  
Further analysis needed here...
```{r govpolicy, echo=FALSE, warning=FALSE, message=FALSE}
##Collingwood
#date_c <- as.Date(collingwood$List.Date, format = "%Y-%m-%d")
date_c <- collingwood$List.Date
sold_date_c <- format(date_c + collingwood$DOM, "%Y/%m")
collingwood$Sold.Date = sold_date_c
collingwood.monthlyprice = data.frame()
collingwood.monthlyavg = data.frame()
avgmonth_c = data.frame()
r=1
for (i in unique(collingwood$Sold.Date)) {
  collingwood.monthlyprice = subset(collingwood, Sold.Date == i)
  monthlyavg_c = mean(collingwood.monthlyprice$Price)
  avgmonth_c[r,1] = i
  avgmonth_c[r,2] = monthlyavg_c
  r = r+1
}
avgmonth_c$V1 = paste0(avgmonth_c$V1, "/01")
avgmonth_c$V1 = as.Date(avgmonth_c$V1, format = "%Y/%m/%d")
avgmonth_c = avgmonth_c[order(avgmonth_c$V1),]

govpolicy=read.csv("../STAT450_STAT550_RealEstate/STAT450_analysis/Government Policies.csv")
govpolicy=govpolicy[order(as.Date(govpolicy$Date.YYYY.MM.DD.)),]
policydate=govpolicy$Date.YYYY.MM.DD.
policydate <- policydate[!is.na(policydate)]

cols=c("Financing Crisis"="red","BC Investment Immigration Program"="Blue","Empty Homes Tax"="Green","First Time Home Buyers' Program"="Orange","15% Foreign Buyer Tax"="Yellow")

## WORKS ON CONSOLE BUT NOT ON KNIT!!!

# ggplot(avgmonth_c, aes(x = avgmonth_c$V1, y = avgmonth_c$V2)) +
#   geom_line() +
#   geom_vline(aes(xintercept = policydate[1], color = "Financing Crisis")) +
#   geom_vline(aes(xintercept = policydate[2], color = "BC Investment Immigration Program")) +
#   geom_vline(aes(xintercept = policydate[3], color = "Empty Homes Tax")) +
#   geom_vline(aes(xintercept = policydate[4], color = "First Time Home Buyers' Program")) +
#   geom_vline(aes(xintercept = policydate[5], color = "15% Foreign Buyer Tax")) +
#   scale_color_manual(name = "Gov Policies", values = cols) +
#   xlab("Month") + ylab("Monthly Average Price") + ggtitle(label = "Government Policy Effect")
```
```{r stupid3, echo=FALSE, warning=FALSE, message=FALSE}

# ggplot(avgmonth_c, aes(x = avgmonth_c$V1, y = avgmonth_c$V2)) +
#   geom_line() +
#   geom_vline(aes(xintercept = policydate[1], color = as.character(cols["Financing Crisis"]))) +
#   geom_vline(aes(xintercept = policydate[2], color = as.character(cols["BC Investment Immigration Program"]))) +
#   geom_vline(aes(xintercept = policydate[3], color = as.character(cols["Empty Homes Tax"]))) +
#   geom_vline(aes(xintercept = policydate[4], color = as.character(cols["First Time Home Buyers' Program"]))) +
#   geom_vline(aes(xintercept = policydate[5], color = as.character(cols["15% Foreign Buyer Tax"]))) +
#   #scale_color_manual(name = "Gov Policies", values = cols) +
#   xlab("Month") + ylab("Monthly Average Price") + ggtitle(label = "Government Policy Effect")
```
```{r stupid4, echo=FALSE, warning=FALSE, message=FALSE}

# avgmonth_c_15_17 = subset(avgmonth_c, V1 >= as.Date("2015-01-01"))
# ggplot(avgmonth_c_15_17, aes(x = avgmonth_c_15_17$V1, y = avgmonth_c_15_17$V2)) + geom_line() + 
#   geom_vline(aes(xintercept = policydate[2], color = "BC Investment Immigration Program")) +
#   geom_vline(aes(xintercept = policydate[3], color = "Empty Homes Tax")) +
#   geom_vline(aes(xintercept = policydate[4], color = "First Time Home Buyers' Program")) +
#   geom_vline(aes(xintercept = policydate[5], color = "15% Foreign Buyer Tax")) +
#   scale_color_manual(name = "Gov Policies", values = cols[2:5]) +
#   xlab("Month") + ylab("Monthly Average Price") + ggtitle(label = "Government Policy Effect 2015-2017")

##Metrotown
date_m <- as.Date(metrotown$List.Date) 
sold_date_m <- format(as.Date(date_m + metrotown$DOM), "%Y/%m")
metrotown$Sold.Date = sold_date_m
metrotown.monthlyprice = data.frame()
metrotown.monthlyavg = data.frame()
avgmonth_m = data.frame()
r=1
for (i in unique(metrotown$Sold.Date)) {
  metrotown.monthlyprice = subset(metrotown, Sold.Date == i)
  monthlyavg_m = mean(metrotown.monthlyprice$Price)
  avgmonth_m[r,1] = i
  avgmonth_m[r,2] = monthlyavg_m
  r = r+1
}
avgmonth_m$V1 = paste0(avgmonth_m$V1, "/01")
avgmonth_m$V1 = as.Date(avgmonth_m$V1, format = "%Y/%m/%d")
avgmonth_m = avgmonth_m[order(avgmonth_m$V1),]


```
```{r stupid2, echo=FALSE, warning=FALSE, message=FALSE}


# ggplot(avgmonth_m, aes(x = avgmonth_m$V1, y = avgmonth_m$V2)) +
#   geom_line() + 
#   geom_vline(aes(xintercept = policydate[1], color = "Financing Crisis")) +
#   geom_vline(aes(xintercept = policydate[2], color = "BC Investment Immigration Program")) +
#   geom_vline(aes(xintercept = policydate[3], color = "Empty Homes Tax")) +
#   geom_vline(aes(xintercept = policydate[4], color = "First Time Home Buyers' Program")) +
#   geom_vline(aes(xintercept = policydate[5], color = "15% Foreign Buyer Tax")) +
#   scale_color_manual(name = "Gov Policies", values = cols) +
#   xlab("Month") + ylab("Monthly Average Price") + ggtitle(label = "Government Policy Effect")

# avgmonth_m_15_17 = subset(avgmonth_m, V1 >= as.Date("2015-01-01"))
# ggplot(avgmonth_m_15_17, aes(x = avgmonth_m_15_17$V1, y = avgmonth_m_15_17$V2)) + geom_line() + 
#   geom_vline(aes(xintercept = policydate[2], color = "BC Investment Immigration Program")) +
#   geom_vline(aes(xintercept = policydate[3], color = "Empty Homes Tax")) +
#   geom_vline(aes(xintercept = policydate[4], color = "First Time Home Buyers' Program")) +
#   geom_vline(aes(xintercept = policydate[5], color = "15% Foreign Buyer Tax")) +
#   scale_color_manual(name = "Gov Policies", values = cols[2:5]) +
#   xlab("Month") + ylab("Monthly Average Price") + ggtitle(label = "Government Policy Effect 2015-2017")

##Whalley
date_w <- as.Date(whalley$List.Date) 
sold_date_w <- format(as.Date(date_w + whalley$DOM), "%Y/%m")
whalley$Sold.Date = sold_date_w
whalley.monthlyprice = data.frame()
whalley.monthlyavg = data.frame()
avgmonth_w = data.frame()
r=1
for (i in unique(whalley$Sold.Date)) {
  whalley.monthlyprice = subset(whalley, Sold.Date == i)
  monthlyavg_w = mean(whalley.monthlyprice$Price)
  avgmonth_w[r,1] = i
  avgmonth_w[r,2] = monthlyavg_w
  r = r+1
}
avgmonth_w$V1 = paste0(avgmonth_w$V1, "/01")
avgmonth_w$V1 = as.Date(avgmonth_w$V1, format = "%Y/%m/%d")
avgmonth_w = avgmonth_w[order(avgmonth_w$V1),]

# ggplot(avgmonth_w, aes(x = avgmonth_w$V1, y = avgmonth_w$V2)) +
#   geom_line() + 
#   geom_vline(aes(xintercept = policydate[1], color = "Financing Crisis")) +
#   geom_vline(aes(xintercept = policydate[2], color = "BC Investment Immigration Program")) +
#   geom_vline(aes(xintercept = policydate[3], color = "Empty Homes Tax")) +
#   geom_vline(aes(xintercept = policydate[4], color = "First Time Home Buyers' Program")) +
#   geom_vline(aes(xintercept = policydate[5], color = "15% Foreign Buyer Tax")) +
#   scale_color_manual(name = "Gov Policies", values = cols) +
#   xlab("Month") + ylab("Monthly Average Price") + ggtitle(label = "Government Policy Effect")

# avgmonth_w_15_17 = subset(avgmonth_w, V1 >= as.Date("2015-01-01"))
# ggplot(avgmonth_w_15_17, aes(x = avgmonth_w_15_17$V1, y = avgmonth_w_15_17$V2)) + geom_line() + 
#   geom_vline(aes(xintercept = policydate[2], color = "BC Investment Immigration Program")) +
#   geom_vline(aes(xintercept = policydate[3], color = "Empty Homes Tax")) +
#   geom_vline(aes(xintercept = policydate[4], color = "First Time Home Buyers' Program")) +
#   geom_vline(aes(xintercept = policydate[5], color = "15% Foreign Buyer Tax")) +
#   scale_color_manual(name = "Gov Policies", values = cols[2:5]) +
#   xlab("Month") + ylab("Monthly Average Price") + ggtitle(label = "Government Policy Effect 2015-2017")

```
  


## Results: ARIMA


```{r load packges, message=FALSE, warning=FALSE, echo=FALSE}
#library('lubridate')
library('ggplot2')
library('tseries')
library('forecast')
```

```{r subset_data, echo=FALSE}
#Process full_data into a data frame with columns "sold_date" and "average Sold.Price.per.SqFt"
#sold_date(year/month) = List.Date + DOM

load("clean_data.RData")
date <- as.Date(full_data$List.Date, "%m/%d/%Y") 
sold_date <- format(date + full_data$DOM,format = "%Y/%m")
full_data <- cbind(full_data, sold_date)

collingwood <- subset(full_data, Neighborhood == "Collingwood")
metrotown <-subset(full_data, Neighborhood == "Metrotown")
whalley <-subset(full_data, Neighborhood == "Whalley")

#month <- strftime(date, "%m")
#year <- strftime(date, "%Y")
#day <- strftime(date, "%d")

#aggregate Sold.Price.per.SqFt by sold_date(year/month)
c_sold_price <- aggregate(collingwood$Sold.Price.per.SqFt, list(collingwood$sold_date), mean)
m_sold_price <- aggregate(metrotown$Sold.Price.per.SqFt, list(metrotown$sold_date), mean)
w_sold_price <- aggregate(whalley$Sold.Price.per.SqFt, list(whalley$sold_date), mean)

#dim(c_sold_date) = 144 rows and 2 columns
names(c_sold_price) <- c("date","price")
names(m_sold_price) <- c("date","price")
names(w_sold_price) <- c("date","price")
```

```{r analysis function, echo=FALSE}
make_plots <- function(sold_price){
  # data examination
  
  # make a time series object
  ma = ts(na.omit(sold_price$price), frequency=12)
  
  # decomposition of data into seasonal effect, trend, and error
  decomp = stl(ma, s.window="periodic")
  # plot(decomp)
  
  # use auto.arima to find the best set of parameters for ARIMA based on AIC and make 3 predictions
  # Note: FOR ARIMA shorter windows increase your parameter risk while longer windows increase your model risk  
  
  train = auto.arima(ma[-c(142:144)], D=1)
  prediction <- forecast(train,h=3)
  plot(prediction, main="")
  lines(ts(ma))

  # this code is not needed when using auto.arima
  # acf = Acf(ma, main='')
  # pacf = Pacf(ma, main='')
  # print(adf.test(ma, alternative = "stationary"))
  # filtered_ma <- seasadj(decomp)
  # diff1 = diff(filtered_ma, differences = 1)
  # print(adf.test(diff1, alternative = "stationary"))
  # plot2 = plot(diff1)
  # acf2 = Acf(diff1, "Differenced Time Series")
  # pacf2 = Pacf(diff1, "Differenced Time Series")
  
  #return(list(decomp_plot))
}
```

#### Collingwood
```{r collingwood, echo=FALSE, warning=FALSE}
#ggplot(c_sold_price, aes(x = date, y = price)) +  ggtitle("Collingwood") + geom_point() + theme(axis.text.x=element_blank()) 
make_plots(c_sold_price)
```

#### Metrotown
```{r metrotown, echo=FALSE, warning=FALSE}
#ggplot(m_sold_price, aes(x = date, y = price)) + ggtitle("Metrotown") + geom_point() + theme(axis.text.x=element_blank())
make_plots(m_sold_price)
```

#### Whalley
```{r whalley, echo=FALSE, warning=FALSE}
#ggplot(w_sold_price, aes(x = date, y = price)) + ggtitle("Whalley")+ geom_point() + theme(axis.text.x=element_blank())
make_plots(w_sold_price)
```


For Collingwood and Whalley, our fitted ARIMA models were able to predict prices within the 95% and 80% confidence bounds. For Metrotown, however, the fitted ARIMA model was not able to make accurate predictions. We believe that inaccuracies in these ARIMA predictions can be due to new events that cannot be captured in our model, such as a new government policy or a change in the economy.


## Results: Random Forest

```{r random_forest_data, echo=FALSE, warning=FALSE, message=FALSE}
options(warn = 0)
##library("lubridate")
load("clean_data.RData")

full_data$Sold.Date <- full_data$List.Date + full_data$DOM
full_data$SoldYear <- as.numeric(format(full_data$Sold.Date,"%Y"))
full_data$SoldMonth <- as.numeric(format(full_data$Sold.Date,"%m"))

#may need to change the following condition
outlier <- which(full_data$Age >= 999 | is.na(full_data$Price) | is.na(full_data$Sold.Price.per.SqFt) | is.na(full_data$DOM))
full_data <- full_data[-outlier,]

#may need to consider including/excluding other columns such as List.Date
subset_data <- subset(full_data, select=-c(S.A, PicCount, Pics, ML.., Status, Address, List.Date, Sold.Date, TypeDwel, List.Sales.Rep.1...Agent.Full.Name, Age.Type))

# replace NA parking with -1 (treat as separate category)
subset_data$TotalPrkng <- replace(subset_data$TotalPrkng, is.na(subset_data$TotalPrkng), -1)

# deal with non prev sold properties
subset_data$Prev.Price <- replace(subset_data$Prev.Price, is.na(subset_data$Prev.Price), 0)
subset_data$Prev.Sold <- subset_data$Prev.Price != 0

# deal with NA strata maintenance fees
subset_data$StratMtFee <- replace(subset_data$StratMtFee, is.na(subset_data$StratMtFee), 0)


#subset_data[ (subset_data$TotalPrkng > 2), c("TotalPrkng")] <- 3 # 3 == other
#subset_data[ (subset_data$Age >=0 & subset_data$Age <=10), c("Age")] <- "0to10"
#subset_data[ (subset_data$Age >=11 & subset_data$Age <=20), c("Age")] <- "11to20"
#subset_data[ (subset_data$Age >=21 & subset_data$Age <=30), c("Age")] <- "21to30"
#subset_data[ (subset_data$Age >=31 & subset_data$Age <=40), c("Age")] <- "31to40"
#subset_data[ (subset_data$Age >=41), c("Age")] <- "other"

#subset_data[ (subset_data$Yr.Blt < 1990), c("Yr.Blt")] <- "1911-1990"


subset_data$Tot.BR <- as.factor(subset_data$Tot.BR)
subset_data$Tot.Baths <- as.factor(subset_data$Tot.Baths)
#subset_data$Age <- as.factor(subset_data$Age)
#subset_data$Yr.Blt <- as.factor(subset_data$Yr.Blt)
subset_data$TotalPrkng <- as.factor(subset_data$TotalPrkng)
subset_data$Neighborhood <- as.factor(subset_data$Neighborhood)

subset_data$Age <- as.numeric(subset_data$Age)
subset_data$Prev.Sold <- as.factor(subset_data$Prev.Sold)


# group rare bylaw restrictions
#table(subset_data$Bylaw.Restrictions)
subset_data$Bylaw.Restrictions <- as.character(subset_data$Bylaw.Restrictions)
subset_data$Bylaw.Restrictions = paste0(subset_data$Bylaw.Restrictions, ',')

subset_data$Pets.Allowed = grepl("Pets Allowed,", subset_data$Bylaw.Restrictions)
subset_data$Rentals.Allowed = grepl("Rentals Allowed,", subset_data$Bylaw.Restrictions)
subset_data$Age.Restrictions = grepl("Age Restrictions,", subset_data$Bylaw.Restrictions)
subset_data$Smoking.Restrictions = grepl("Smoking Restrictions,", subset_data$Bylaw.Restrictions)
subset_data$Pets.Allowed.Rst = grepl("Pets Allowed w/Rest.,", subset_data$Bylaw.Restrictions)
subset_data$Rentals.Allowed.Rst = grepl("Rentals Allwd w/Restrctns,", subset_data$Bylaw.Restrictions)

subset_data$Pets.Allowed <- as.factor(subset_data$Pets.Allowed)
subset_data$Rentals.Allowed <- as.factor(subset_data$Rentals.Allowed)
subset_data$Age.Restrictions <- as.factor(subset_data$Age.Restrictions)
subset_data$Smoking.Restrictions <- as.factor(subset_data$Smoking.Restrictions)
subset_data$Pets.Allowed.Rst <- as.factor(subset_data$Pets.Allowed.Rst)
subset_data$Rentals.Allowed.Rst <- as.factor(subset_data$Rentals.Allowed.Rst)

subset_data <- subset(subset_data, select=-c(Bylaw.Restrictions, Yr.Blt, Prev.Status))


collingwood <- subset(subset_data, Neighborhood == "Collingwood")
metrotown <-subset(subset_data, Neighborhood == "Metrotown")
whalley <-subset(subset_data, Neighborhood == "Whalley")
```

```{r random forest, echo=FALSE, warning=FALSE, message=FALSE}
library('randomForest')

performCV <- function(district, ntree) {
  y <- as.vector(district$Sold.Price.per.SqFt)
  xm <- model.matrix(~., data = subset(district, select = -c(Sold.Price.per.SqFt, Neighborhood, Price)))
  n <- nrow(xm)
  k <- 2
  ii <- (1:n)%%k + 1
  set.seed(321)
  N <- 5
  mspe <- rep(0, N)  
  prmspe <- rep(0, N)
  for (i in 1:N) {
    ii <- sample(ii)
    pr <- rep(0, n)
    for (j in 1:k) {
      rf=randomForest(x = xm[ii != j, ], y=y[ii != j], xtest=xm[ii == j, ],ytest=y[ii == j], ntree=ntree)
      pr[ii == j] <- rf$test$predicted
    }
    mspe[i] <- mean((district$Sold.Price.per.SqFt - pr)^2)
    prmspe[i] <- mean(abs(district$Sold.Price.per.SqFt - pr)/pr)
  }
  return(rbind(mspe,prmspe))
}


performCV2 <- function(district, ntree) {
  y <- as.vector(district$Sold.Price.per.SqFt)
  n <- length(y)
  district_ <- subset(district, select = -c(Sold.Price.per.SqFt, Neighborhood, Price))
  k <- 2
  ii <- (1:n)%%k + 1
  set.seed(321)
  N <- 5
  mspe <- rep(0, N)
  prmspe <- rep(0, N)
  for (i in 1:N) {
    ii <- sample(ii)
    pr <- rep(0, n)
    for (j in 1:k) {
      rf=randomForest(x = district_[ii != j, ], y=y[ii != j], xtest=district_[ii == j, ],ytest=y[ii == j], ntree=ntree)
      pr[ii == j] <- rf$test$predicted
    }
    mspe[i] <- mean((district$Sold.Price.per.SqFt - pr)^2)
    prmspe[i] <- mean(abs(district$Sold.Price.per.SqFt - pr)/pr)
  }
  return(rbind(mspe,prmspe))
}
```

We supplied variables that could be related to condo prices in order to build a random forest model. We excluded variables that we think are irrelevant for prediction, such as agent name and MLS number. The remaining variables that were considered in the model are:

- Days on Market
- Previous Status
- Strata Maintenance Fee
- Number of Bedrooms
- Number of Bathrooms
- Age
- Locker
- Number of Parking Spaces
- Previous Sold Price / Status
- Sold Year
- Sold Month
- Total Floor Area
- Bylaw Restrictions (such as pet allowance)

```{r RMSE, echo=FALSE, warning=FALSE, message=FALSE}
MSPE2_collingwood = performCV2(collingwood, 100)
MSPE2_metrotown = performCV2(metrotown, 100)
MSPE2_whalley = performCV2(whalley, 100)

print("RMSE for Collingwood: ")
mean(MSPE2_collingwood[2,])
print("RMSE for Metrotown: ")
mean(MSPE2_metrotown[2,])
print("RMSE for Whalley: ")
mean(MSPE2_whalley[2,])
```

The root mean squared error is a good indicator of the relative error of our prediction. Using random forest with 100 trees, along with cross validation, we have found that our root-mean-squared prediction error is **6.7% for Collingwood, 7.8% for Metrotown, and 7.7% for Whalley**. 

To put that into perspective, if we consider a standard 2 bed 2 bath new condo with various characteristics in Collingwood, our prediction might give a price of \$750 per sqft, but that is subject to an error of 0.067*750 ~= \$50. So the predicted price is anywhere between \$700 and \$800 per sqft. In our next report, we will attempt to minimize this prediction error by including external variables and reviewing the data processing. 

Let us take a look at the variable importance of these random forest models by district:

```{r analysis, echo=FALSE, warning=FALSE, message=FALSE}
library(Hmisc)

plotVarImp <- function(district, ntree) {
  y <- as.vector(district$Sold.Price.per.SqFt)
  district_ <- subset(district, select = -c(Sold.Price.per.SqFt, Neighborhood, Price))
  rf=randomForest(x = district_, y=y, ntree=ntree)
  varImpPlot(rf, main = paste(capitalize(deparse(substitute(district))), "Variable Importance"))
}

plotVarImp(collingwood, 100)

print("INSERT INDENT")

plotVarImp(metrotown, 100)

print("INSERT INDENT")

plotVarImp(whalley, 100)
```

We can see that the sold year comes out as one of the most impactful variable in the random forest model for all districts. This is expected, since as we know, all condo prices have increased rapidly over the past few years. However, notice that some of the other variables that stand out are age, total floor area, strata fee, and in particular, whether rentals are allowed. We expected some of the top variables to show up are floor area, age, but we did not expect the restriction on rental to be near the top of the list of top variables. This can certainly be a variable to consider when predicting the price of a potential condo. In many of these cases, total bedroom and bathrooms did not appear near the top of the list. We believe this is due to their overlapping similarities with total floor area, because condos with greater floor area tend to have more bedrooms and bathrooms. 

## Conclusions

Among all the external factors we analyzed, we have seen that the currency exchange rate, BC Investment Immigration Program and the 15% Foreign Buyer Tax had the most powerful impact on the real estate market. Surprisingly, the Foreign Buyer Tax boosted the condo market for all three sub-regions, which was the opposite of what it supposed to do. On the other hand, "First Time Home Buyers' Program" and "Empty Homes Tax" did not seem to improve the housing affordability. We would like to perform further tests to see it their influences were statistically significant.

The fitted ARIMA model was able to make relatively accurate predicitions for Collingwood and Whalley, but it did not perform well for Metrotown. One of the limitations of ARIMA is that if a new event that has not been observed in the past occurs, ARIMA can fail to capture it and make a poor prediction. We believe that this was the case for predicting the price for Metrotown. We will perform further analysis to check this. In addition, we intend to include additional external variables, such as government policies, when fitting the ARIMA model in order to visualize their effects on the trend.

Random forest have given us a preliminary performance with a root-mean-squared prediction error of 6.7% for Collingwood, 7.8% for Metrotown, and 7.7% for Whalley. To improve the model, we will include external variables such as interest rate and school rating. For our next report, we are also looking to see if the distance to skytrain has a relationship with the price.

